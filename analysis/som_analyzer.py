"""
M√≥dulo avan√ßado de an√°lise e visualiza√ß√£o do SOM (Self-Organizing Maps)
Vers√£o melhorada com an√°lises mais profundas e visualiza√ß√µes profissionais
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.ndimage import label, gaussian_filter, gaussian_gradient_magnitude
from scipy import stats
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import pandas as pd
import logging
from typing import Dict, Tuple, Optional, List, Any
import warnings

warnings.filterwarnings('ignore')

# Configura√ß√£o de estilo para visualiza√ß√µes
plt.style.use('default')
sns.set_palette("husl")

logger = logging.getLogger(__name__)

class KohonenAdvancedAnalyzer:
    """Analisador avan√ßado para visualiza√ß√µes e interpreta√ß√£o do SOM"""
    
    def __init__(self):
        self.umatrix = None
        self.activation_map = None
        self.natural_clusters = None
        self.component_planes = None
        self.quality_metrics = {}
        self.feature_names = None

    def create_comprehensive_visualizations(self, som, X, original_features=None, 
                                         feature_names=None):
        """
        Cria visualiza√ß√µes abrangentes e profissionais da rede de Kohonen
        
        Args:
            som: Rede SOM treinada
            X: Dados de entrada (DataFrame ou array)
            original_features: DataFrame original com features completas
            feature_names: Nomes das features para labeling
        """
        logger.info("üé® GERANDO VISUALIZA√á√ïES AVAN√áADAS DO SOM")

        if som is None:
            raise ValueError("Rede SOM n√£o treinada!")

        # Prepara√ß√£o dos dados
        data = self._prepare_data(X)
        self.feature_names = feature_names or getattr(X, 'columns', None)

        # Calcular m√©tricas de qualidade
        self._calculate_quality_metrics(som, data)

        # Criar visualiza√ß√µes em grid organizado
        self._create_analysis_dashboard(som, data, original_features)

        logger.info("‚úÖ Visualiza√ß√µes avan√ßadas salvas com sucesso!")

    def _prepare_data(self, X):
        """Prepara dados para an√°lise"""
        if hasattr(X, 'values'):
            return X.values.astype(np.float32)
        return X.astype(np.float32)

    def _calculate_quality_metrics(self, som, data):
        """Calcula m√©tricas de qualidade do SOM"""
        logger.info("   üìä Calculando m√©tricas de qualidade...")
        
        try:
            # Quantization Error
            q_error = som.quantization_error(data)
            self.quality_metrics['quantization_error'] = q_error
            
            # Topographic Error (aproximado)
            t_error = self._calculate_topographic_error(som, data)
            self.quality_metrics['topographic_error'] = t_error
            
            # Dist√¢ncia m√©dia na U-Matrix
            if hasattr(som, 'distance_map'):
                umatrix = som.distance_map()
                self.quality_metrics['umatrix_mean'] = np.mean(umatrix)
                self.quality_metrics['umatrix_std'] = np.std(umatrix)
            
            logger.info(f"   ‚úÖ M√©tricas: QE={q_error:.4f}, TE={t_error:.4f}")
            
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è  Erro no c√°lculo de m√©tricas: {e}")

    def _calculate_topographic_error(self, som, data, sample_fraction=0.1):
        """Calcula erro topogr√°fico aproximado"""
        try:
            n_samples = int(len(data) * sample_fraction)
            indices = np.random.choice(len(data), n_samples, replace=False)
            topographic_errors = 0
            
            for idx in indices:
                sample = data[idx]
                w = som.winner(sample)
                # Encontrar segundo BMU seria mais preciso, mas esta √© uma aproxima√ß√£o
                distances = np.linalg.norm(som._weights - sample, axis=2)
                sorted_indices = np.unravel_index(np.argsort(distances.ravel()), distances.shape)
                
                # Verificar se os dois BMUs mais pr√≥ximos s√£o adjacentes
                bmu1 = (sorted_indices[0][0], sorted_indices[1][0])
                bmu2 = (sorted_indices[0][1], sorted_indices[1][1])
                
                # Verificar adjac√™ncia (simplificado)
                distance_bmus = np.sqrt((bmu1[0]-bmu2[0])**2 + (bmu1[1]-bmu2[1])**2)
                if distance_bmus > 1.5:  # N√£o s√£o adjacentes
                    topographic_errors += 1
            
            return topographic_errors / n_samples
            
        except Exception:
            return 0.0  # Fallback

    def _create_analysis_dashboard(self, som, data, original_features):
        """Cria dashboard completo de an√°lise"""
        logger.info("   üìà Criando dashboard de an√°lise...")
        
        # Figura principal com subplots organizados
        fig = plt.figure(figsize=(25, 20))
        
        # 1. U-Matrix avan√ßada
        ax1 = plt.subplot(3, 4, 1)
        self._create_enhanced_umatrix(som, ax1)
        
        # 2. Mapa de ativa√ß√£o
        ax2 = plt.subplot(3, 4, 2)
        self._create_enhanced_activation_map(som, data, ax2)
        
        # 3. Clusters naturais
        ax3 = plt.subplot(3, 4, 3)
        self.natural_clusters = self._create_natural_clusters(som, data, ax3)
        
        # 4. Component Planes (primeiras 4 features)
        ax4 = plt.subplot(3, 4, 4)
        self._create_component_planes(som, ax4, num_components=4)
        
        # 5. An√°lise de qualidade
        ax5 = plt.subplot(3, 4, 5)
        self._create_quality_visualization(ax5)
        
        # 6. Histograma de ativa√ß√£o
        ax6 = plt.subplot(3, 4, 6)
        self._create_activation_histogram(ax6)
        
        # 7. Mapa de gradiente
        ax7 = plt.subplot(3, 4, 7)
        self._create_gradient_map(som, ax7)
        
        # 8. Proje√ß√£o dos dados (se poss√≠vel)
        ax8 = plt.subplot(3, 4, 8)
        self._create_data_projection(data, ax8)
        
        # 9. Matriz de correla√ß√£o de neur√¥nios
        ax9 = plt.subplot(3, 4, 9)
        self._create_neuron_correlation(som, ax9)
        
        # 10. Evolu√ß√£o do aprendizado (se dispon√≠vel)
        ax10 = plt.subplot(3, 4, 10)
        self._create_learning_analysis(ax10)
        
        # 11. Distribui√ß√£o de clusters
        ax11 = plt.subplot(3, 4, 11)
        self._create_cluster_distribution(ax11)
        
        # 12. Resumo executivo
        ax12 = plt.subplot(3, 4, 12)
        self._create_executive_summary(ax12)
        
        plt.tight_layout()
        plt.savefig('kohonen_comprehensive_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # Visualiza√ß√µes adicionais em arquivos separados
        self._create_individual_visualizations(som, data, original_features)

    def _create_enhanced_umatrix(self, som, ax):
        """Cria U-Matrix avan√ßada com m√∫ltiplas camadas de informa√ß√£o"""
        try:
            if hasattr(som, 'distance_map'):
                self.umatrix = som.distance_map().T
            else:
                # Calcular U-Matrix manualmente se necess√°rio
                self.umatrix = self._compute_umatrix(som)
            
            # Plot principal
            im = ax.imshow(self.umatrix, cmap='viridis', aspect='auto', 
                          interpolation='hanning')
            
            # Adicionar contornos
            levels = np.linspace(self.umatrix.min(), self.umatrix.max(), 15)
            contour = ax.contour(self.umatrix, levels=levels, colors='white', 
                               alpha=0.3, linewidths=0.5)
            
            ax.set_title('U-Matrix: Mapa de Dist√¢ncias\n(Estrutura Topol√≥gica)', 
                        fontsize=11, fontweight='bold', pad=10)
            ax.set_xlabel('Coordenada X')
            ax.set_ylabel('Coordenada Y')
            
            # Adicionar barra de cores
            plt.colorbar(im, ax=ax, label='Dist√¢ncia M√©dia', shrink=0.8)
            
        except Exception as e:
            self._plot_error(ax, f"Erro na U-Matrix: {str(e)}")

    def _compute_umatrix(self, som):
        """Calcula U-Matrix manualmente se necess√°rio"""
        weights = som._weights
        umatrix = np.zeros((weights.shape[0], weights.shape[1]))
        
        for i in range(weights.shape[0]):
            for j in range(weights.shape[1]):
                neighbors = []
                # Coletar vizinhos
                for dx, dy in [(-1,0), (1,0), (0,-1), (0,1)]:
                    ni, nj = i + dx, j + dy
                    if 0 <= ni < weights.shape[0] and 0 <= nj < weights.shape[1]:
                        neighbors.append(weights[ni, nj])
                
                if neighbors:
                    dists = [np.linalg.norm(weights[i,j] - n) for n in neighbors]
                    umatrix[i,j] = np.mean(dists)
        
        return umatrix
    
    # Adicione este m√©todo para calcular m√©tricas com amostragem
    def compute_quality_metrics_safe(self, som, data, sample_size=10000):
        """Calcula m√©tricas de qualidade com amostragem para evitar problemas de mem√≥ria"""
        if len(data) > sample_size:
            # Usar amostra aleat√≥ria
            indices = np.random.choice(len(data), sample_size, replace=False)
            sample_data = data[indices]
        else:
            sample_data = data
        
        try:
            q_error = som.quantization_error(sample_data)
        except MemoryError:
            # Fallback: calcular manualmente em lotes
            q_error = self._batch_quantization_error(som, sample_data)
        
        try:
            t_error = som.topographic_error(sample_data)
        except MemoryError:
            # Para TE, usar amostra ainda menor
            if len(sample_data) > 5000:
                indices = np.random.choice(len(sample_data), 5000, replace=False)
                t_error = som.topographic_error(sample_data[indices])
            else:
                t_error = som.topographic_error(sample_data)
        
        return q_error, t_error

    def _batch_quantization_error(self, som, data, batch_size=1000):
        """Calcula QE em lotes"""
        total_distance = 0.0
        n_batches = int(np.ceil(len(data) / batch_size))
        
        for i in range(n_batches):
            batch_start = i * batch_size
            batch_end = min((i + 1) * batch_size, len(data))
            batch = data[batch_start:batch_end]
            
            # Calcular dist√¢ncia para cada ponto do batch
            for j, x in enumerate(batch):
                winner = som.winner(x)
                weight = som._weights[winner]
                total_distance += np.linalg.norm(x - weight)
        
        return total_distance / len(data)

    def _create_enhanced_activation_map(self, som, data, ax):
        """Cria mapa de ativa√ß√£o avan√ßado"""
        try:
            # Calcular mapa de ativa√ß√£o
            self.activation_map = np.zeros((som._weights.shape[0], som._weights.shape[1]))
            
            # Processamento em batch para efici√™ncia
            batch_size = min(5000, len(data))
            for i in range(0, len(data), batch_size):
                end_idx = min(i + batch_size, len(data))
                batch = data[i:end_idx]
                
                for sample in batch:
                    winner = som.winner(sample)
                    self.activation_map[winner] += 1
            
            # Suaviza√ß√£o para melhor visualiza√ß√£o
            smoothed_activation = gaussian_filter(self.activation_map, sigma=0.8)
            
            # Plot
            im = ax.imshow(smoothed_activation.T, cmap='hot', aspect='auto',
                          interpolation='bicubic')
            
            # Adicionar contornos de densidade
            if np.max(smoothed_activation) > 0:
                levels = np.linspace(smoothed_activation.min(), 
                                   smoothed_activation.max(), 8)
                contour = ax.contour(smoothed_activation.T, levels=levels, 
                                   colors='white', alpha=0.5, linewidths=1)
            
            ax.set_title('Mapa de Densidade de Ativa√ß√£o\n(Pontos por Neur√¥nio)', 
                        fontsize=11, fontweight='bold', pad=10)
            ax.set_xlabel('Coordenada X')
            ax.set_ylabel('Coordenada Y')
            
            plt.colorbar(im, ax=ax, label='Densidade de Pontos', shrink=0.8)
            
        except Exception as e:
            self._plot_error(ax, f"Erro no mapa de ativa√ß√£o: {str(e)}")

    def _create_natural_clusters(self, som, data, ax, density_threshold=0.6):
        """Identifica clusters naturais usando Watershed algorithm"""
        try:
            # Calcular U-Matrix se n√£o dispon√≠vel
            if self.umatrix is None:
                if hasattr(som, 'distance_map'):
                    self.umatrix = som.distance_map().T
                else:
                    self.umatrix = self._compute_umatrix(som)
            
            # 1. Normalizar U-Matrix
            umat_norm = (self.umatrix - self.umatrix.min()) / (self.umatrix.max() - self.umatrix.min())
            
            # 2. Usar watershed do scikit-image se dispon√≠vel
            try:
                from skimage.segmentation import watershed
                from skimage.filters import sobel
                
                # Calcular gradiente
                gradient = sobel(umat_norm)
                
                # Encontrar marcadores
                from skimage.feature import peak_local_max
                coordinates = peak_local_max(umat_norm, min_distance=2, threshold_rel=0.3)
                
                markers = np.zeros_like(umat_norm, dtype=np.int32)
                for i, (x, y) in enumerate(coordinates):
                    markers[x, y] = i + 1
                
                # Aplicar watershed
                clusters = watershed(gradient, markers)
                
            except ImportError:
                # Fallback: usar algoritmo mais simples
                clusters = self._simple_clustering(umat_norm, threshold=0.5)
            
            # Converter para formato compat√≠vel
            labeled_array = clusters
            
            # Contar clusters (excluir 0 que √© background)
            unique_clusters = np.unique(labeled_array)
            num_clusters = len(unique_clusters[unique_clusters != 0])
            
            logger.info(f"   üìä Identificados {num_clusters} clusters naturais")
            
            # Visualiza√ß√£o
            background = ax.imshow(self.umatrix, cmap='gray', alpha=0.4, aspect='auto')
            
            # Criar mapa de cores para clusters
            colors = plt.cm.tab20(np.linspace(0, 1, num_clusters + 1))
            
            for cluster_id in unique_clusters:
                if cluster_id == 0:
                    continue
                    
                cluster_mask = labeled_array == cluster_id
                y_coords, x_coords = np.where(cluster_mask)
                
                if len(x_coords) >= 2:  # Cluster deve ter pelo menos 2 neur√¥nios
                    # Centroide
                    centroid_x = np.mean(x_coords)
                    centroid_y = np.mean(y_coords)
                    
                    # Plotar cluster
                    scatter = ax.scatter(x_coords, y_coords, 
                                       color=colors[cluster_id % len(colors)],
                                       label=f'C{cluster_id}',
                                       alpha=0.7, s=30, edgecolors='white', linewidth=0.5)
                    
                    # Adicionar label do cluster
                    ax.text(centroid_x, centroid_y, str(cluster_id),
                           fontsize=9, fontweight='bold', ha='center', va='center',
                           bbox=dict(boxstyle="circle,pad=0.2", facecolor='white', 
                                   alpha=0.8, edgecolor='black'))
            
            ax.set_title(f'Clusters Naturais por Densidade\n{num_clusters} Clusters Identificados',
                        fontsize=11, fontweight='bold', pad=10)
            ax.set_xlabel('Coordenada X')
            ax.set_ylabel('Coordenada Y')
            
            # Legenda se n√£o for muitos clusters
            if num_clusters <= 15:
                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
            
            return labeled_array
            
        except Exception as e:
            logger.error(f"Erro nos clusters: {e}")
            # Fallback: usar k-means simples nos neur√¥nios
            return self._fallback_clustering(som, data, ax)

    def _simple_clustering(self, umat_norm, threshold=0.5):
        """Clustering simples baseado em threshold"""
        # Encontrar regi√µes abaixo do threshold (vales)
        valleys = umat_norm < threshold
        
        # Rotular componentes conectados
        from scipy.ndimage import label
        labeled_array, num_features = label(valleys)
        
        return labeled_array

    def _fallback_clustering(self, som, data, ax, n_clusters=10):
        """Fallback usando k-means nos BMUs"""
        from sklearn.cluster import KMeans
        
        # Calcular BMUs para uma amostra
        sample_size = min(5000, len(data))
        indices = np.random.choice(len(data), sample_size, replace=False)
        sample_data = data[indices]
        
        # Obter BMUs
        bmus = []
        for sample in sample_data:
            winner = som.winner(sample)
            bmus.append(winner)
        
        bmus_array = np.array(bmus)
        
        # Aplicar k-means
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        cluster_labels = kmeans.fit_predict(bmus_array)
        
        # Criar mapa de clusters
        cluster_map = np.zeros((som._weights.shape[0], som._weights.shape[1]), dtype=int)
        
        # Mapear cada BMU para sua posi√ß√£o no mapa
        for i, (x, y) in enumerate(bmus_array):
            cluster_map[x, y] = cluster_labels[i] + 1
        
        # Plotar
        ax.imshow(self.umatrix, cmap='gray', alpha=0.4, aspect='auto')
        
        for cluster_id in range(1, n_clusters + 1):
            y_coords, x_coords = np.where(cluster_map == cluster_id)
            if len(x_coords) > 0:
                ax.scatter(x_coords, y_coords, 
                          color=plt.cm.tab20(cluster_id / n_clusters),
                          label=f'C{cluster_id}', alpha=0.7, s=30)
        
        ax.set_title(f'Clusters por K-Means (Fallback)\n{n_clusters} Clusters',
                    fontsize=11, fontweight='bold')
         
        return cluster_map

    def _create_component_planes(self, som, ax, num_components=4):
        """Cria visualiza√ß√£o de component planes para features importantes"""
        try:
            weights = som._weights
            
            if self.feature_names is None:
                self.feature_names = [f'Feature_{i}' for i in range(weights.shape[2])]
            
            # Selecionar features com maior vari√¢ncia
            feature_vars = np.var(weights.reshape(-1, weights.shape[2]), axis=0)
            top_features = np.argsort(feature_vars)[-num_components:][::-1]
            
            # Configurar subplots
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            axes = axes.flatten()
            
            for idx, (feature_idx, ax_comp) in enumerate(zip(top_features, axes)):
                feature_plane = weights[:, :, feature_idx]
                
                im = ax_comp.imshow(feature_plane.T, cmap='coolwarm', aspect='auto',
                                  interpolation='nearest')
                
                feature_name = self.feature_names[feature_idx]
                ax_comp.set_title(f'{feature_name}\n(Var: {feature_vars[feature_idx]:.3f})',
                                fontsize=10, fontweight='bold')
                ax_comp.set_xlabel('X')
                ax_comp.set_ylabel('Y')
                
                plt.colorbar(im, ax=ax_comp, shrink=0.8)
            
            plt.tight_layout()
            plt.savefig('kohonen_component_planes.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            # Para o dashboard, mostrar apenas o primeiro component plane
            if len(top_features) > 0:
                first_feature = top_features[0]
                feature_plane = weights[:, :, first_feature]
                
                im = ax.imshow(feature_plane.T, cmap='coolwarm', aspect='auto')
                ax.set_title(f'Component Plane: {self.feature_names[first_feature]}',
                           fontsize=11, fontweight='bold', pad=10)
                ax.set_xlabel('Coordenada X')
                ax.set_ylabel('Coordenada Y')
                plt.colorbar(im, ax=ax, label='Valor do Peso', shrink=0.8)
            
        except Exception as e:
            self._plot_error(ax, f"Erro nos component planes: {str(e)}")

    def _create_quality_visualization(self, ax):
        """Visualiza√ß√£o das m√©tricas de qualidade"""
        try:
            metrics = self.quality_metrics
            if not metrics:
                ax.text(0.5, 0.5, 'M√©tricas n√£o dispon√≠veis', 
                       ha='center', va='center', transform=ax.transAxes)
                ax.set_title('M√©tricas de Qualidade', fontsize=11)
                return
            
            # Preparar dados para bar plot
            metric_names = []
            metric_values = []
            colors = []
            
            for name, value in metrics.items():
                metric_names.append(name.replace('_', ' ').title())
                metric_values.append(value)
                # Cores baseadas no tipo de m√©trica
                if 'error' in name.lower():
                    colors.append('lightcoral')
                else:
                    colors.append('lightsteelblue')
            
            # Criar bar plot
            bars = ax.bar(metric_names, metric_values, color=colors, alpha=0.7)
            
            # Adicionar valores nas barras
            for bar, value in zip(bars, metric_values):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                       f'{value:.4f}', ha='center', va='bottom', fontsize=9)
            
            ax.set_title('M√©tricas de Qualidade do SOM', fontsize=11, fontweight='bold', pad=10)
            ax.set_ylabel('Valor da M√©trica')
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3, axis='y')
            
        except Exception as e:
            self._plot_error(ax, f"Erro nas m√©tricas: {str(e)}")

    def _create_activation_histogram(self, ax):
        """Histograma da distribui√ß√£o de ativa√ß√µes"""
        try:
            if self.activation_map is not None:
                activations = self.activation_map.flatten()
                activations = activations[activations > 0]  # Filtrar zeros
                
                if len(activations) > 0:
                    ax.hist(activations, bins=20, alpha=0.7, color='skyblue', 
                           edgecolor='black')
                    ax.set_title('Distribui√ß√£o de Ativa√ß√µes por Neur√¥nio', 
                               fontsize=11, fontweight='bold', pad=10)
                    ax.set_xlabel('N√∫mero de Pontos')
                    ax.set_ylabel('Frequ√™ncia')
                    ax.grid(True, alpha=0.3)
                    
                    # Adicionar estat√≠sticas
                    mean_act = np.mean(activations)
                    ax.axvline(mean_act, color='red', linestyle='--', 
                              label=f'M√©dia: {mean_act:.1f}')
                    ax.legend()
                else:
                    ax.text(0.5, 0.5, 'Sem ativa√ß√µes', 
                           ha='center', va='center', transform=ax.transAxes)
            else:
                ax.text(0.5, 0.5, 'Mapa de ativa√ß√£o n√£o dispon√≠vel', 
                       ha='center', va='center', transform=ax.transAxes)
                
        except Exception as e:
            self._plot_error(ax, f"Erro no histograma: {str(e)}")

    def _create_gradient_map(self, som, ax):
        """Mapa de gradiente para mostrar fronteiras"""
        try:
            if self.umatrix is not None:
                gradient = gaussian_gradient_magnitude(self.umatrix, sigma=1.0)
                
                im = ax.imshow(gradient, cmap='Reds', aspect='auto')
                ax.set_title('Mapa de Gradiente\n(Fronteiras entre Clusters)',
                           fontsize=11, fontweight='bold', pad=10)
                ax.set_xlabel('Coordenada X')
                ax.set_ylabel('Coordenada Y')
                plt.colorbar(im, ax=ax, label='Magnitude do Gradiente', shrink=0.8)
            else:
                ax.text(0.5, 0.5, 'U-Matrix n√£o dispon√≠vel', 
                       ha='center', va='center', transform=ax.transAxes)
                
        except Exception as e:
            self._plot_error(ax, f"Erro no gradiente: {str(e)}")

    def _create_data_projection(self, data, ax):
        """Proje√ß√£o dos dados em 2D usando PCA/t-SNE"""
        try:
            if len(data) > 1000:
                # Amostrar para performance
                indices = np.random.choice(len(data), 1000, replace=False)
                sample_data = data[indices]
            else:
                sample_data = data
            
            if sample_data.shape[1] > 2:
                # Usar PCA para redu√ß√£o dimensional
                pca = PCA(n_components=2, random_state=42)
                projection = pca.fit_transform(sample_data)
                method = 'PCA'
            else:
                projection = sample_data
                method = 'Original'
            
            scatter = ax.scatter(projection[:, 0], projection[:, 1], 
                               alpha=0.6, s=20, c='purple')
            ax.set_title(f'Proje√ß√£o dos Dados ({method})', 
                        fontsize=11, fontweight='bold', pad=10)
            ax.set_xlabel(f'Componente 1')
            ax.set_ylabel(f'Componente 2')
            ax.grid(True, alpha=0.3)
            
        except Exception as e:
            self._plot_error(ax, f"Erro na proje√ß√£o: {str(e)}")

    def _create_neuron_correlation(self, som, ax):
        """Matriz de correla√ß√£o entre neur√¥nios"""
        try:
            weights = som._weights
            flattened_weights = weights.reshape(-1, weights.shape[2])
            
            # Calcular correla√ß√£o entre vetores de peso
            correlation_matrix = np.corrcoef(flattened_weights)
            
            im = ax.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', 
                          vmin=-1, vmax=1)
            ax.set_title('Correla√ß√£o entre Neur√¥nios', 
                        fontsize=11, fontweight='bold', pad=10)
            ax.set_xlabel('√çndice do Neur√¥nio')
            ax.set_ylabel('√çndice do Neur√¥nio')
            plt.colorbar(im, ax=ax, label='Coeficiente de Correla√ß√£o', shrink=0.8)
            
        except Exception as e:
            self._plot_error(ax, f"Erro na correla√ß√£o: {str(e)}")

    def _create_learning_analysis(self, ax):
        """An√°lise do processo de aprendizado (placeholder)"""
        ax.text(0.5, 0.5, 'An√°lise de Aprendizado\n(N√£o dispon√≠vel nesta vers√£o)',
               ha='center', va='center', transform=ax.transAxes, fontsize=10)
        ax.set_title('An√°lise do Processo de Aprendizado', 
                    fontsize=11, fontweight='bold', pad=10)
        ax.set_frame_on(False)
        ax.set_xticks([])
        ax.set_yticks([])

    def _create_cluster_distribution(self, ax):
        """Distribui√ß√£o de tamanhos dos clusters"""
        try:
            if self.natural_clusters is not None:
                cluster_ids, cluster_sizes = np.unique(self.natural_clusters, return_counts=True)
                
                # Filtrar cluster 0 (background) e clusters pequenos
                valid_mask = (cluster_ids > 0) & (cluster_sizes >= 2)
                valid_clusters = cluster_ids[valid_mask]
                valid_sizes = cluster_sizes[valid_mask]
                
                if len(valid_clusters) > 0:
                    colors = plt.cm.Set3(np.linspace(0, 1, len(valid_clusters)))
                    bars = ax.bar(valid_clusters, valid_sizes, color=colors, alpha=0.7)
                    
                    ax.set_title('Distribui√ß√£o de Tamanhos dos Clusters',
                               fontsize=11, fontweight='bold', pad=10)
                    ax.set_xlabel('ID do Cluster')
                    ax.set_ylabel('N√∫mero de Neur√¥nios')
                    ax.grid(True, alpha=0.3, axis='y')
                    
                    # Adicionar valores
                    for bar, size in zip(bars, valid_sizes):
                        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.1,
                               f'{size}', ha='center', va='bottom', fontsize=8)
                else:
                    ax.text(0.5, 0.5, 'Sem clusters v√°lidos', 
                           ha='center', va='center', transform=ax.transAxes)
            else:
                ax.text(0.5, 0.5, 'Clusters n√£o calculados', 
                       ha='center', va='center', transform=ax.transAxes)
                
        except Exception as e:
            self._plot_error(ax, f"Erro na distribui√ß√£o: {str(e)}")

    def _create_executive_summary(self, ax):
        """Resumo executivo das an√°lises"""
        ax.set_frame_on(False)
        ax.set_xticks([])
        ax.set_yticks([])
        
        summary_text = "RESUMO EXECUTIVO\n\n"
        
        # M√©tricas de qualidade
        if self.quality_metrics:
            q_error = self.quality_metrics.get('quantization_error', 'N/A')
            t_error = self.quality_metrics.get('topographic_error', 'N/A')
            summary_text += f"Qualidade:\n"
            summary_text += f"‚Ä¢ Erro de Quantiza√ß√£o: {q_error:.4f}\n"
            summary_text += f"‚Ä¢ Erro Topogr√°fico: {t_error:.4f}\n\n"
        
        # Informa√ß√µes de clusters
        if self.natural_clusters is not None:
            cluster_ids = np.unique(self.natural_clusters)
            num_clusters = len(cluster_ids[cluster_ids > 0])
            summary_text += f"Clusters:\n"
            summary_text += f"‚Ä¢ N√∫mero: {num_clusters}\n"
        
        # Informa√ß√µes de ativa√ß√£o
        if self.activation_map is not None:
            total_activations = np.sum(self.activation_map)
            active_neurons = np.sum(self.activation_map > 0)
            total_neurons = self.activation_map.size
            
            summary_text += f"\nAtiva√ß√£o:\n"
            summary_text += f"‚Ä¢ Total pontos: {int(total_activations)}\n"
            summary_text += f"‚Ä¢ Neur√¥nios ativos: {active_neurons}/{total_neurons}\n"
            summary_text += f"‚Ä¢ Taxa ativa√ß√£o: {active_neurons/total_neurons*100:.1f}%"
        
        ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=10,
               verticalalignment='top', fontfamily='monospace',
               bbox=dict(boxstyle="round,pad=0.5", facecolor='lightblue', alpha=0.7))

    def _create_individual_visualizations(self, som, data, original_features):
        """Cria visualiza√ß√µes individuais de alta qualidade"""
        # U-Matrix detalhada
        self._create_detailed_umatrix(som)
        
        # Clusters detalhados
        self._create_detailed_clusters(som, data)
        
        # Component planes completos
        self._create_all_component_planes(som)

    def _create_detailed_umatrix(self, som):
        """Cria visualiza√ß√£o detalhada da U-Matrix"""
        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6))
        
        # U-Matrix padr√£o
        im1 = ax1.imshow(self.umatrix, cmap='viridis', aspect='auto')
        ax1.set_title('U-Matrix - Vis√£o Geral', fontsize=12, fontweight='bold')
        plt.colorbar(im1, ax=ax1)
        
        # U-Matrix com contornos
        im2 = ax2.imshow(self.umatrix, cmap='plasma', aspect='auto')
        levels = np.linspace(self.umatrix.min(), self.umatrix.max(), 15)
        contour = ax2.contour(self.umatrix, levels=levels, colors='white', alpha=0.6)
        ax2.clabel(contour, inline=True, fontsize=8)
        ax2.set_title('U-Matrix com Contornos', fontsize=12, fontweight='bold')
        plt.colorbar(im2, ax=ax2)
        
        # U-Matrix 3D (se poss√≠vel)
        try:
            from mpl_toolkits.mplot3d import Axes3D
            X, Y = np.meshgrid(range(self.umatrix.shape[1]), range(self.umatrix.shape[0]))
            ax3 = fig.add_subplot(133, projection='3d')
            surf = ax3.plot_surface(X, Y, self.umatrix, cmap='coolwarm', 
                                  alpha=0.8, linewidth=0)
            ax3.set_title('U-Matrix 3D', fontsize=12, fontweight='bold')
            plt.colorbar(surf, ax=ax3, shrink=0.6)
        except ImportError:
            ax3.text(0.5, 0.5, '3D n√£o dispon√≠vel', ha='center', va='center', 
                    transform=ax3.transAxes)
            ax3.set_title('U-Matrix 3D (N√£o dispon√≠vel)', fontsize=12)
        
        plt.tight_layout()
        plt.savefig('kohonen_detailed_umatrix.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _create_detailed_clusters(self, som, data):
        """Cria visualiza√ß√£o detalhada dos clusters"""
        if self.natural_clusters is None:
            return
            
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))
        
        # Clusters com U-Matrix de fundo
        background = ax1.imshow(self.umatrix, cmap='gray', alpha=0.3, aspect='auto')
        
        cluster_ids = np.unique(self.natural_clusters)
        colors = plt.cm.tab20(np.linspace(0, 1, len(cluster_ids)))
        
        for cluster_id in cluster_ids:
            if cluster_id == 0:
                continue
                
            cluster_mask = self.natural_clusters == cluster_id
            y_coords, x_coords = np.where(cluster_mask)
            
            if len(x_coords) > 0:
                ax1.scatter(x_coords, y_coords, color=colors[cluster_id], 
                          label=f'Cluster {cluster_id}', s=50, alpha=0.8)
                
                # Centroide
                centroid_x = np.mean(x_coords)
                centroid_y = np.mean(y_coords)
                ax1.text(centroid_x, centroid_y, str(cluster_id), 
                        fontsize=10, fontweight='bold', ha='center', va='center',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9))
        
        ax1.set_title('Clusters Naturais - Visualiza√ß√£o Detalhada', 
                     fontsize=14, fontweight='bold')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # Histograma de clusters
        cluster_sizes = []
        for cluster_id in cluster_ids:
            if cluster_id > 0:
                size = np.sum(self.natural_clusters == cluster_id)
                cluster_sizes.append(size)
        
        if cluster_sizes:
            ax2.bar(range(1, len(cluster_sizes) + 1), cluster_sizes, 
                   color=plt.cm.Set3(np.linspace(0, 1, len(cluster_sizes))))
            ax2.set_title('Distribui√ß√£o de Tamanhos dos Clusters', 
                         fontsize=14, fontweight='bold')
            ax2.set_xlabel('Cluster ID')
            ax2.set_ylabel('N√∫mero de Neur√¥nios')
            ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('kohonen_detailed_clusters.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _create_all_component_planes(self, som):
        """Cria component planes para todas as features"""
        weights = som._weights
        n_features = weights.shape[2]
        
        if self.feature_names is None:
            self.feature_names = [f'Feature_{i}' for i in range(n_features)]
        
        # Calcular layout do grid
        n_cols = 4
        n_rows = (n_features + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4 * n_rows))
        axes = axes.flatten() if n_features > 1 else [axes]
        
        for i in range(n_features):
            ax = axes[i]
            feature_plane = weights[:, :, i]
            
            im = ax.imshow(feature_plane.T, cmap='coolwarm', aspect='auto')
            ax.set_title(f'{self.feature_names[i]}', fontsize=10, fontweight='bold')
            ax.set_xlabel('X')
            ax.set_ylabel('Y')
            
            plt.colorbar(im, ax=ax, shrink=0.8)
        
        # Ocultar eixos vazios
        for i in range(n_features, len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        plt.savefig('kohonen_all_component_planes.png', dpi=300, bbox_inches='tight')
        plt.close()

    def _plot_error(self, ax, message):
        """Plota mensagem de erro em um subplot"""
        ax.text(0.5, 0.5, message, ha='center', va='center', 
               transform=ax.transAxes, fontsize=9, color='red')
        ax.set_frame_on(False)
        ax.set_xticks([])
        ax.set_yticks([])

    def get_neuron_clusters(self):
        """Retorna os clusters dos neur√¥nios"""
        return self.natural_clusters

    def get_quality_metrics(self):
        """Retorna as m√©tricas de qualidade calculadas"""
        return self.quality_metrics.copy()

    def generate_analysis_report(self, output_file='som_analysis_report.txt'):
        """Gera relat√≥rio completo da an√°lise"""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("RELAT√ìRIO DE AN√ÅLISE DO SOM\n")
            f.write("=" * 50 + "\n\n")
            
            # M√©tricas de qualidade
            f.write("M√âTRICAS DE QUALIDADE:\n")
            f.write("-" * 30 + "\n")
            for name, value in self.quality_metrics.items():
                f.write(f"{name.replace('_', ' ').title()}: {value:.6f}\n")
            
            f.write("\n")
            
            # Informa√ß√µes de clusters
            if self.natural_clusters is not None:
                cluster_ids = np.unique(self.natural_clusters)
                num_clusters = len(cluster_ids[cluster_ids > 0])
                f.write(f"CLUSTERS NATURAIS: {num_clusters} clusters identificados\n")
                
                for cluster_id in cluster_ids:
                    if cluster_id > 0:
                        size = np.sum(self.natural_clusters == cluster_id)
                        f.write(f"  ‚Ä¢ Cluster {cluster_id}: {size} neur√¥nios\n")
            
            f.write("\n")
            
            # Estat√≠sticas de ativa√ß√£o
            if self.activation_map is not None:
                total_activations = np.sum(self.activation_map)
                active_neurons = np.sum(self.activation_map > 0)
                total_neurons = self.activation_map.size
                
                f.write("ESTAT√çSTICAS DE ATIVA√á√ÉO:\n")
                f.write("-" * 30 + "\n")
                f.write(f"Total de ativa√ß√µes: {int(total_activations)}\n")
                f.write(f"Neur√¥nios ativos: {active_neurons}/{total_neurons} "
                       f"({active_neurons/total_neurons*100:.1f}%)\n")
                f.write(f"Ativa√ß√µes por neur√¥nio: {total_activations/active_neurons:.1f} (m√©dia)\n")
            
            f.write("\nRECOMENDA√á√ïES:\n")
            f.write("-" * 30 + "\n")
            
            if self.quality_metrics.get('quantization_error', 1) > 0.5:
                f.write("‚Ä¢ Considerar aumentar o n√∫mero de √©pocas de treinamento\n")
            
            if self.quality_metrics.get('topographic_error', 1) > 0.2:
                f.write("‚Ä¢ A topografia pode ser melhorada ajustando a taxa de aprendizado\n")
            
            if self.natural_clusters is not None and len(np.unique(self.natural_clusters)) <= 2:
                f.write("‚Ä¢ Poucos clusters identificados - considerar ajustar par√¢metros de densidade\n")
        
        logger.info(f"   üìÑ Relat√≥rio de an√°lise salvo em: {output_file}")